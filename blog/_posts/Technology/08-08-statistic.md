
###统计与分布
1. 加和值，平均值，标准差，加权均值，众数，中位数，欧氏距离，曼哈顿距离
2. 高斯分布（miu，sigma） 
3. 泊松分布（lambda，k）
    描述单位时间内随机事件发生的次数。lambda：单位时间内随机事件的平均发生率
    在一个标准时间里，发生这件事的发生率是lambda次，哪发生k次的概率是泊松分布。
4. 伯努利分布（p）

###信息论
1. 信息量
2. 香农公式  $C = B* log_2(1+\frac{S}{N})$

    C：信道中信号传输的速度 B：码元速率的极限值（B=2H） S：信号功率 N：噪声功率

3. 信息熵：*信息杂乱程度的量化描述*
    
    $H(x)= -\displaystyle\sum_{i=1}^n p(x_i)log_2 P(x_i)$

    在信息可能有N种情况是，如果每种情况出现的概率相等，那么N越大，信息熵越大。
    在信息可能有N重的情况是，当N一定，那么其中所有情况概率相等时信息熵是最大的，如果有一种情况的概率比其他情况概率大很多，那么信息熵会很小。

    >信息越确定，越单一，信息熵越小。

    >信息越不确定，越混乱，信息熵越大。

    信息增益是特征选择中的一个重要指标，它定义为一个特征能够为分类系统带来多少信息，带来的信息越多，该特征越重要。

###回归

倒退，倒推，由果索因，归纳：当看到大量事实所呈现的样态，推断出原因是如何的；看到大量数字对的样态，推断出他们之间蕴含的关系。

1. 线性回归
2. 残差分析

###聚类
1. K-Means 算法
2. 层次聚类
3. 聚类评估
    + 聚类趋势：霍普金斯统计量（0.5 vs 1）
    + 簇数确定：$\sqrt{\frac{n}{2}}$ ; 肘方法

###分类

1. 朴素贝叶斯
2. 决策树归纳
